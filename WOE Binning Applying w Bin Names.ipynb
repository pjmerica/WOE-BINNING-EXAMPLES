{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e69a935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pjmer\\anaconda4\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Feb 12 03:31:03 PM: Encountered unexpected exception importing solver GLOP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.11.4210). Expected < 9.10.0. Please open a feature request on cvxpy to enable support for this version.')\n",
      "(CVXPY) Feb 12 03:31:03 PM: Encountered unexpected exception importing solver PDLP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.11.4210). Expected < 9.10.0. Please open a feature request on cvxpy to enable support for this version.')\n",
      "   numeric_feature1_woe  numeric_feature2_woe  categorical_feature1_woe  \\\n",
      "0              0.039567             -0.322896                  0.037823   \n",
      "1              0.039567              0.055338                 -0.099822   \n",
      "2             -0.055267             -0.093279                  0.037823   \n",
      "3              0.039567             -0.093279                  0.037823   \n",
      "4             -0.104586              0.694702                  0.037823   \n",
      "\n",
      "   categorical_feature2_woe  boolean_feature_woe  ordinal_feature_woe  \n",
      "0                 -0.021234            -0.012774            -0.012833  \n",
      "1                  0.022034             0.013039            -0.012833  \n",
      "2                 -0.021234            -0.012774            -0.072308  \n",
      "3                  0.022034             0.013039             0.086297  \n",
      "4                  0.022034            -0.012774            -0.072308  \n"
     ]
    }
   ],
   "source": [
    "from optbinning import OptimalBinning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create example training dataset\n",
    "np.random.seed(42)\n",
    "train_data = pd.DataFrame({\n",
    "    \"numeric_feature1\": np.random.uniform(0, 100, 1000),\n",
    "    \"numeric_feature2\": np.random.uniform(10, 50, 1000),\n",
    "    \"categorical_feature1\": np.random.choice([\"A\", \"B\", \"C\"], size=1000),\n",
    "    \"categorical_feature2\": np.random.choice([\"X\", \"Y\"], size=1000),\n",
    "    \"boolean_feature\": np.random.choice([True, False], size=1000),\n",
    "    \"ordinal_feature\": np.random.choice([1, 2, 3, 4], size=1000),\n",
    "    \"target\": np.random.randint(0, 2, 1000)  # Binary target\n",
    "})\n",
    "\n",
    "# Create a new dataset (simulating unseen test data)\n",
    "new_data = pd.DataFrame({\n",
    "    \"numeric_feature1\": np.random.uniform(0, 100, 500),\n",
    "    \"numeric_feature2\": np.random.uniform(10, 50, 500),\n",
    "    \"categorical_feature1\": np.random.choice([\"A\", \"B\", \"C\"], size=500),\n",
    "    \"categorical_feature2\": np.random.choice([\"X\", \"Y\"], size=500),\n",
    "    \"boolean_feature\": np.random.choice([True, False], size=500),\n",
    "    \"ordinal_feature\": np.random.choice([1, 2, 3, 4], size=500)\n",
    "})\n",
    "\n",
    "# Separate features and target in training data\n",
    "X_train = train_data.drop(columns=[\"target\"])\n",
    "y_train = train_data[\"target\"]\n",
    "\n",
    "# Dictionary to store trained binning models\n",
    "binning_models = {}\n",
    "\n",
    "# Train binning models on the training data\n",
    "for feature in X_train.columns:\n",
    "    # Detect feature type\n",
    "    feature_dtype = X_train[feature].dtype\n",
    "\n",
    "    if feature_dtype == \"object\":  # Categorical variables\n",
    "        binning_type = \"categorical\"\n",
    "        monotonic_trend = None\n",
    "    elif np.issubdtype(feature_dtype, np.number):  # Numerical and ordinal variables\n",
    "        binning_type = \"numerical\"\n",
    "        monotonic_trend = \"auto\"\n",
    "    elif feature_dtype == \"bool\":  # Boolean variables\n",
    "        binning_type = \"categorical\"\n",
    "        monotonic_trend = None\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported feature type: {feature_dtype} for feature '{feature}'\")\n",
    "\n",
    "    # Fit binning model\n",
    "    opt_binning = OptimalBinning(name=feature, dtype=binning_type, solver=\"cp\", monotonic_trend=monotonic_trend)\n",
    "    opt_binning.fit(X_train[feature], y_train)\n",
    "\n",
    "    # Store trained binning model\n",
    "    binning_models[feature] = opt_binning\n",
    "\n",
    "# Function to apply trained bins to a new dataset\n",
    "def apply_binning_models(new_data, binning_models):\n",
    "    woe_transformed_df = pd.DataFrame()\n",
    "\n",
    "    for feature, model in binning_models.items():\n",
    "        if feature in new_data.columns:\n",
    "            # Transform feature using pre-trained binning model\n",
    "            woe_values = model.transform(new_data[feature], metric=\"woe\")\n",
    "            woe_transformed_df[f\"{feature}_woe\"] = woe_values\n",
    "\n",
    "    return woe_transformed_df\n",
    "\n",
    "# Apply the trained binning models to the new dataset\n",
    "new_woe_df = apply_binning_models(new_data, binning_models)\n",
    "\n",
    "# Display the first few rows of the transformed dataset\n",
    "print(new_woe_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fec734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b34427ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   numeric_feature1_woe  numeric_feature2_woe  categorical_feature1_woe  \\\n",
      "0              0.039567             -0.322896                  0.037823   \n",
      "1              0.039567              0.055338                 -0.099822   \n",
      "2             -0.055267             -0.093279                  0.037823   \n",
      "3              0.039567             -0.093279                  0.037823   \n",
      "4             -0.104586              0.694702                  0.037823   \n",
      "\n",
      "   categorical_feature2_woe  boolean_feature_woe  ordinal_feature_woe  \n",
      "0                 -0.021234            -0.012774            -0.012833  \n",
      "1                  0.022034             0.013039            -0.012833  \n",
      "2                 -0.021234            -0.012774            -0.072308  \n",
      "3                  0.022034             0.013039             0.086297  \n",
      "4                  0.022034            -0.012774            -0.072308  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to apply trained bins to a new dataset\n",
    "def apply_binning_models(new_data, binning_models):\n",
    "    woe_transformed_df = pd.DataFrame()\n",
    "\n",
    "    for feature, model in binning_models.items():\n",
    "        if feature in new_data.columns:\n",
    "            # Transform feature using pre-trained binning model\n",
    "            woe_values = model.transform(new_data[feature], metric=\"woe\")\n",
    "            woe_transformed_df[f\"{feature}_woe\"] = woe_values\n",
    "\n",
    "    return woe_transformed_df\n",
    "\n",
    "# Apply the trained binning models to the new dataset\n",
    "new_woe_df = apply_binning_models(new_data, binning_models)\n",
    "\n",
    "# Display the first few rows of the transformed dataset\n",
    "print(new_woe_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c705c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'binning_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m binning_model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric_feature2_woe\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'binning_model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7ce5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e375946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting in bin names\n",
    "\n",
    "def apply_binning_models_with_labels(new_data, binning_models):\n",
    "    transformed_df = pd.DataFrame()\n",
    "\n",
    "    for feature, model in binning_models.items():\n",
    "        if feature in new_data.columns:\n",
    "\n",
    "            bin_labels = model.transform(new_data[feature], metric=\"binning\")\n",
    "            woe_values = model.transform(new_data[feature], metric=\"woe\")\n",
    "\n",
    "   \n",
    "            transformed_df[f\"{feature}_bin_label\"] = bin_labels\n",
    "            transformed_df[f\"{feature}_woe\"] = woe_values\n",
    "\n",
    "    return transformed_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c26f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
